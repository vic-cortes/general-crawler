# General Crawler - Job Scrapers

Un sistema de scrapers as√≠ncronos y concurrentes para extraer ofertas de trabajo de m√∫ltiples sitios web mexicanos.

## üöÄ Caracter√≠sticas

- **Scraping As√≠ncrono**: Utiliza `crawl4ai` para scraping web de alto rendimiento
- **Concurrencia Controlada**: Sistema de sem√°foros para limitar browsers simult√°neos
- **Arquitectura Modular**: Sistema de mixins para reutilizar c√≥digo entre scrapers
- **Extracci√≥n Inteligente**: Obtiene detalles completos de cada oferta de trabajo
- **Almacenamiento JSON**: Guarda resultados en formato JSON estructurado

## üìÅ Estructura del Proyecto

```
src/job/
‚îú‚îÄ‚îÄ mixins.py                 # Clases base y mixins compartidos
‚îú‚îÄ‚îÄ occ/
‚îÇ   ‚îî‚îÄ‚îÄ scraper.py           # Scraper para OCC.com.mx
‚îú‚îÄ‚îÄ compu_trabajo/
‚îÇ   ‚îî‚îÄ‚îÄ scraper.py           # Scraper para ComputTrabajo.com
‚îî‚îÄ‚îÄ common/
    ‚îú‚îÄ‚îÄ constants.py         # Constantes compartidas
    ‚îî‚îÄ‚îÄ utils.py             # Utilidades comunes
```

## üèóÔ∏è Arquitectura

### Sistema de Mixins

El proyecto utiliza un sistema de mixins para compartir funcionalidad com√∫n entre scrapers:

#### [`BaseScraperSetup`](src/job/mixins.py)
Clase abstracta que define la interfaz com√∫n para todos los scrapers:
- `service_name`: Nombre del servicio
- `base_selector`: Selector CSS para ofertas
- `key_css_selector`: Selector para esperar carga de p√°gina
- `_output_schema()`: Esquema de extracci√≥n de datos

#### [`AsyncScraperMixin`](src/job/mixins.py)
Proporciona funcionalidad as√≠ncrona compartida:
- `_get_overview()`: Extrae listado de ofertas
- `_get_details()`: Obtiene detalles individuales
- `get_data()`: M√©todo principal de scraping
- `is_next_page_available()`: Verifica p√°ginas disponibles

#### [`BaseScraper`](src/job/mixins.py)
Combina configuraci√≥n base y funcionalidad as√≠ncrona:
- Manejo de sesiones √∫nicas por crawler
- Configuraci√≥n de crawling est√°ndar

#### [`ConcurrentScraperMixin`](src/job/mixins.py)
Implementa scraping concurrente con sem√°foros:
- `scrape_page()`: Scraping de p√°gina individual
- `main_scraper()`: Coordinador de scraping concurrente
- Control de recursos con sem√°foros

### Scrapers Espec√≠ficos

#### OCC Scraper ([`src/job/occ/scraper.py`](src/job/occ/scraper.py))
- **URL Base**: `https://www.occ.com.mx/empleos/de-python/`
- **Paginaci√≥n**: `?page={num}`
- **Especializaci√≥n**: Extracci√≥n de salarios, requisitos y descripciones espec√≠ficas de OCC

#### ComputTrabajo Scraper ([`src/job/compu_trabajo/scraper.py`](src/job/compu_trabajo/scraper.py))
- **URL Base**: `https://mx.computrabajo.com/trabajo-de-python`
- **Paginaci√≥n**: `?p={num}`
- **Especializaci√≥n**: Manejo de estructura espec√≠fica de ComputTrabajo

## ‚ö° Uso

### Ejecuci√≥n B√°sica

```python
# OCC Scraper
python src/job/occ/scraper.py

# ComputTrabajo Scraper
python src/job/compu_trabajo/scraper.py
```

### Ejecuci√≥n Program√°tica

```python
import asyncio
from src.job.occ.scraper import OCCConcurrentScraper
from src.job.compu_trabajo.scraper import ComputTrabajoConcurrentScraper

# OCC con par√°metros personalizados
await OCCConcurrentScraper.run(
    max_pages=50,
    max_concurrent_browsers=5
)

# ComputTrabajo
await ComputTrabajoConcurrentScraper.run(
    max_pages=100,
    max_concurrent_browsers=3
)
```

## üîß Configuraci√≥n

### Par√°metros de Concurrencia

- **`max_pages`**: N√∫mero m√°ximo de p√°ginas a scrapear (default: 100)
- **`max_concurrent_browsers`**: M√°ximo de browsers simult√°neos (default: 3)

### Configuraci√≥n de Browser

La configuraci√≥n del browser se define en [`src/config.py`](src/config.py) mediante `browser_config`.

## üìä Datos Extra√≠dos

Cada oferta incluye:

### Datos B√°sicos
- `title`: T√≠tulo del puesto
- `company`: Nombre de la empresa
- `location`: Ubicaci√≥n del trabajo
- `relative_date`: Fecha de publicaci√≥n
- `description`: Descripci√≥n breve

### Detalles Completos
- `details.description`: Descripci√≥n completa
- `details.requirements`: Requisitos del puesto
- `details.salary`: Informaci√≥n salarial (cuando disponible)
- `details.job_url`: URL directa a la oferta
- `offer_id`: ID √∫nico de la oferta
- `current_datetime`: Timestamp de extracci√≥n

## üìà Mejoras de Rendimiento

### Antes de la Refactorizaci√≥n
- Scraping secuencial p√°gina por p√°gina
- Una sola instancia de browser
- ~360 l√≠neas de c√≥digo duplicado

### Despu√©s de la Refactorizaci√≥n
- **Concurrencia Real**: M√∫ltiples browsers trabajando simult√°neamente
- **Reducci√≥n de C√≥digo**: 48-51% menos l√≠neas por scraper
- **Arquitectura Modular**: Sistema de herencia y mixins
- **Control de Recursos**: Sem√°foros para evitar sobrecarga

## üõ†Ô∏è Desarrollo

### Agregar un Nuevo Scraper

1. Heredar de [`BaseScraper`](src/job/mixins.py):

```python
from src.job.mixins import BaseScraper, ConcurrentScraperMixin

class NuevoScraper(BaseScraper):
    @property
    def service_name(self) -> str:
        return "nuevo_sitio"
    
    @property
    def base_selector(self) -> str:
        return "div.job-offer"
    
    # Implementar m√©todos requeridos...
```

2. Crear clase concurrente:

```python
class NuevoConcurrentScraper(ConcurrentScraperMixin):
    @classmethod
    async def run(cls, max_pages: int = 100, max_concurrent_browsers: int = 3):
        await cls.main_scraper(
            scraper_class=NuevoScraper,
            base_job_url="https://sitio.com/empleos",
            url_pattern="https://sitio.com/empleos?page={page_num}",
            max_pages=max_pages,
            max_concurrent_browsers=max_concurrent_browsers,
        )
```

### Dependencias

- `crawl4ai`: Web crawler as√≠ncrono
- `beautifulsoup4`: Parsing HTML
- `asyncio`: Programaci√≥n as√≠ncrona

## üìù Logs y Debugging

El sistema proporciona logging detallado:

```
Starting async occ scraper with max 3 concurrent browsers
Launching 100 concurrent scraping tasks...
Starting scrape of page 1: https://www.occ.com.mx/empleos/de-python/
Starting scrape of page 2: https://www.occ.com.mx/empleos/de-python/?page=2
...
Completed page 1: found 25 offers
Completed page 2: found 23 offers
...
Scraping completed. Processed 45 pages, found 1,125 total offers
Results saved to: data/occ_job_offers_20260117_13_00.json
Total offers scraped: 1,125
```

## üê≥ Docker

### Construcci√≥n y Ejecuci√≥n

```bash
# Construir la imagen
docker build -t general-crawler .

# Ejecutar todos los scrapers
docker-compose up

# Ejecutar un scraper espec√≠fico
docker-compose run occ-scraper
docker-compose run indeed-scraper
docker-compose run compu-trabajo-scraper

# Ejecutar pruebas
docker-compose --profile test up test
```

### Servicios Disponibles

- **scrapers**: Servicio base con entorno configurado
- **occ-scraper**: Scraper espec√≠fico para OCC.com.mx
- **indeed-scraper**: Scraper espec√≠fico para Indeed
- **compu-trabajo-scraper**: Scraper espec√≠fico para ComputTrabajo
- **test**: Servicio para ejecutar pruebas unitarias

### Variables de Entorno

- `HEADLESS=true`: Ejecutar browser en modo headless
- `LOG_LEVEL=INFO`: Nivel de logging
- `PYTHONPATH=/app`: Path de Python en contenedor

### Vol√∫menes

- `./results:/app/results`: Almacenamiento de resultados
- `./src:/app/src`: C√≥digo fuente para desarrollo

## üö¶ Estado del Proyecto

- ‚úÖ Sistema de mixins implementado
- ‚úÖ Scraping as√≠ncrono y concurrente
- ‚úÖ Control de recursos con sem√°foros
- ‚úÖ Scrapers OCC y ComputTrabajo refactorizados
- ‚úÖ Extracci√≥n de detalles completos
- ‚úÖ Almacenamiento en JSON
- ‚úÖ Soporte Docker completo

## üìÑ Licencia

Este proyecto es de uso interno y educativo.